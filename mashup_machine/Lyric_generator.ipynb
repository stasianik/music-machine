{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stasianik/opt/anaconda3/envs/insight/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/stasianik/opt/anaconda3/envs/insight/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/stasianik/opt/anaconda3/envs/insight/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/stasianik/opt/anaconda3/envs/insight/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/stasianik/opt/anaconda3/envs/insight/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/stasianik/opt/anaconda3/envs/insight/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/stasianik/opt/anaconda3/envs/insight/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/stasianik/opt/anaconda3/envs/insight/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/stasianik/opt/anaconda3/envs/insight/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/stasianik/opt/anaconda3/envs/insight/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/stasianik/opt/anaconda3/envs/insight/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/stasianik/opt/anaconda3/envs/insight/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gpt_2_simple as gpt2\n",
    "from big_phoney import BigPhoney\n",
    "import numpy as np\n",
    "\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "\n",
    "from nlpaug.util import Action\n",
    "# model_name = \"124M\"\n",
    "# model is saved into current directory under /models/124M/\n",
    "# gpt2.download_gpt2(model_name=model_name) #need to run only once. comment out once done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint checkpoint/run1/model-500\n",
      "WARNING:tensorflow:From /Users/stasianik/opt/anaconda3/envs/insight/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-500\n"
     ]
    }
   ],
   "source": [
    "#Initiate TensorFlow session\n",
    "sess = gpt2.start_tf_sess()\n",
    "gpt2.load_gpt2(sess, run_name='run1')\n",
    "\n",
    "#Load text augmentation model\n",
    "aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased', action=\"insert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2.generate(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later on I'll need to add the artist as a parameter, if I have 3, so it can load in the right finetuned model\n",
    "def generate_lyrics(): \n",
    "    \n",
    "    generated_text = gpt2.generate(sess, \n",
    "                     length=250,\n",
    "                     temperature=0.9,\n",
    "                     prefix=\"Deep in the night\",\n",
    "                     nsamples=1,\n",
    "                     batch_size=1,\n",
    "                     return_as_list=True)[0]\n",
    "    \n",
    "    generated_text = generated_text.split(\"\\n\")\n",
    "    \n",
    "    target_lyrics = [\"The snow glows white on the mountain tonight\",\n",
    "    \"Not a footprint to be seen\",\n",
    "    \"A kingdom of isolation\",\n",
    "    \"And it looks like I'm the queen\",\n",
    "    \"The wind is howling like this swirling storm inside\",\n",
    "    \"Couldn't keep it in, heaven knows I've tried\",\n",
    "    \"Don't let them in, don't let them see\",\n",
    "    \"Be the good girl you always have to be\",\n",
    "    \"Conceal, don't feel, don't let them know\",\n",
    "    \"Well, now they know\",\n",
    "    \"Let it go, let it go\",\n",
    "    \"Can't hold it back anymore\",\n",
    "    \"Let it go, let it go\",\n",
    "    \"Turn away and slam the door\",\n",
    "    \"I don't care what they're going to say\",\n",
    "    \"Let the storm rage on\",\n",
    "    \"The cold never bothered me anyway\"]\n",
    "    \n",
    "    return generated_text, target_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = generate_lyrics()\n",
    "gen_lyrics = lyrics[0]\n",
    "target_lyrics = lyrics[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Deep in the night is death, stepping out into the empty-hell street', 'crushing metal, ripping skin, ripping bones', 'the end is closing in', 'moving too fast', 'metal skeleton, metallica skeleton', 'crushing bass solo, crushing vocals', 'frantic riding on shotgun, neckbeast wreck', 'heavy rings finger, finger of sandbell shake', 'wrecked by the world, sea of gold', 'desperate, youll pay, changing forever', 'scan the horizon, the clouds are passing by', 'scan the horizon, the clouds are passing by', 'scan the horizon', 'scan the horizon daddy', 'scan the horizon', 'scan the horizon', 'im frantic in your frantic riding', 'i see red', 'in the mean time', 'have you got the treasure?', 'in the mean time', 'ride on shotgun, for your future', 'planning on riding on your shoulders', 'then my envy and my derision', 'scan the horizon, the clouds are passing by', 'scan the horizon, the clouds are passing by', 'scan the horizon', 'scan the horizon', 'scan the horizon', 'scan the horizon feel so alive', 'sure to lose your mind in the endless repeating', 'feel so alive in the endless repeating', 'scan the horizon, the clouds are passing by', 'scan the horizon, the']\n"
     ]
    }
   ],
   "source": [
    "print(gen_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syls(text):\n",
    "    \n",
    "    phoney = BigPhoney()\n",
    "    gen_schema = []\n",
    "    \n",
    "    for line in text:\n",
    "         syls = phoney.count_syllables(line)\n",
    "         gen_schema.append(syls)\n",
    "         print(syls,line)\n",
    "        \n",
    "    return gen_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 Deep in the night is death, stepping out into the empty-hell street\n",
      "10 crushing metal, ripping skin, ripping bones\n",
      "6 the end is closing in\n",
      "4 moving too fast\n",
      "12 metal skeleton, metallica skeleton\n",
      "9 crushing bass solo, crushing vocals\n",
      "WARNING:tensorflow:From /Users/stasianik/opt/anaconda3/envs/insight/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/stasianik/opt/anaconda3/envs/insight/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/stasianik/opt/anaconda3/envs/insight/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "10 frantic riding on shotgun, neckbeast wreck\n",
      "11 heavy rings finger, finger of sandbell shake\n",
      "7 wrecked by the world, sea of gold\n",
      "9 desperate, youll pay, changing forever\n",
      "11 scan the horizon, the clouds are passing by\n",
      "11 scan the horizon, the clouds are passing by\n",
      "5 scan the horizon\n",
      "7 scan the horizon daddy\n",
      "5 scan the horizon\n",
      "5 scan the horizon\n",
      "9 im frantic in your frantic riding\n",
      "3 i see red\n",
      "4 in the mean time\n",
      "6 have you got the treasure?\n",
      "4 in the mean time\n",
      "8 ride on shotgun, for your future\n",
      "9 planning on riding on your shoulders\n",
      "9 then my envy and my derision\n",
      "11 scan the horizon, the clouds are passing by\n",
      "11 scan the horizon, the clouds are passing by\n",
      "5 scan the horizon\n",
      "5 scan the horizon\n",
      "5 scan the horizon\n",
      "9 scan the horizon feel so alive\n",
      "12 sure to lose your mind in the endless repeating\n",
      "11 feel so alive in the endless repeating\n",
      "11 scan the horizon, the clouds are passing by\n",
      "6 scan the horizon, the\n",
      "[16, 10, 6, 4, 12, 9, 10, 11, 7, 9, 11, 11, 5, 7, 5, 5, 9, 3, 4, 6, 4, 8, 9, 9, 11, 11, 5, 5, 5, 9, 12, 11, 11, 6]\n"
     ]
    }
   ],
   "source": [
    "gen_schema = count_syls(gen_lyrics)\n",
    "print(gen_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 The snow glows white on the mountain tonight\n",
      "7 Not a footprint to be seen\n",
      "8 A kingdom of isolation\n",
      "7 And it looks like I'm the queen\n",
      "12 The wind is howling like this swirling storm inside\n",
      "10 Couldn't keep it in, heaven knows I've tried\n",
      "8 Don't let them in, don't let them see\n",
      "10 Be the good girl you always have to be\n",
      "8 Conceal, don't feel, don't let them know\n",
      "4 Well, now they know\n",
      "6 Let it go, let it go\n",
      "7 Can't hold it back anymore\n",
      "6 Let it go, let it go\n",
      "7 Turn away and slam the door\n",
      "9 I don't care what they're going to say\n",
      "5 Let the storm rage on\n",
      "10 The cold never bothered me anyway\n",
      "[10, 7, 8, 7, 12, 10, 8, 10, 8, 4, 6, 7, 6, 7, 9, 5, 10]\n"
     ]
    }
   ],
   "source": [
    "target_schema = count_syls(target_lyrics)\n",
    "print(target_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16, 10, 6, 4, 12, 9, 10, 11, 7, 9, 11, 11, 5, 7, 5, 5, 9] 17 17\n"
     ]
    }
   ],
   "source": [
    "target_len = len(target_schema)\n",
    "del gen_schema[target_len:]\n",
    "print(gen_schema, len(gen_schema), len(target_schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Deep in the night is death, stepping out into the empty-hell street', 'crushing metal, ripping skin, ripping bones', 'the end is closing in', 'moving too fast', 'metal skeleton, metallica skeleton', 'crushing bass solo, crushing vocals', 'frantic riding on shotgun, neckbeast wreck', 'heavy rings finger, finger of sandbell shake', 'wrecked by the world, sea of gold', 'desperate, youll pay, changing forever', 'scan the horizon, the clouds are passing by', 'scan the horizon, the clouds are passing by', 'scan the horizon', 'scan the horizon daddy', 'scan the horizon', 'scan the horizon', 'im frantic in your frantic riding'] 17\n"
     ]
    }
   ],
   "source": [
    "del gen_lyrics[target_len:]\n",
    "print(gen_lyrics, len(gen_lyrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving too fast\n",
      "5\n",
      "Original:\n",
      "moving too fast\n",
      "Augmented Text:\n",
      "keep moving too fast\n",
      "5\n",
      "Original:\n",
      "moving too fast\n",
      "Augmented Text:\n",
      "moving too damn fast\n",
      "5\n",
      "Original:\n",
      "moving too fast\n",
      "Augmented Text:\n",
      "moving too damn fast\n",
      "5\n",
      "Original:\n",
      "moving too fast\n",
      "Augmented Text:\n",
      "moving way too fast\n",
      "4\n",
      "Original:\n",
      "moving too fast\n",
      "Augmented Text:\n",
      "\" moving too fast\n",
      "5\n",
      "Original:\n",
      "moving too fast\n",
      "Augmented Text:\n",
      "just moving too fast\n",
      "5\n",
      "Original:\n",
      "moving too fast\n",
      "Augmented Text:\n",
      "moving too damn fast\n",
      "5\n",
      "Original:\n",
      "moving too fast\n",
      "Augmented Text:\n",
      "moving too damn fast\n",
      "5\n",
      "Original:\n",
      "moving too fast\n",
      "Augmented Text:\n",
      "moving too damn fast\n",
      "6\n",
      "Original:\n",
      "moving too fast\n",
      "Augmented Text:\n",
      "moving ever too fast\n",
      "8\n",
      "Original:\n",
      "moving too fast\n",
      "Augmented Text:\n",
      "moving entirely too fast\n",
      "8\n",
      "Target acquired:\n",
      "7\n",
      "Final line is:\n",
      "moving too fast\n"
     ]
    }
   ],
   "source": [
    "# aug = naw.ContextualWordEmbsAug(\n",
    "#     model_path='bert-base-uncased', action=\"insert\")\n",
    "a = 3\n",
    "line = gen_lyrics[a]\n",
    "#augmented_text = aug.augment(test)\n",
    "print(line)\n",
    "print(\"Target:\")\n",
    "print(target_schema[a])\n",
    "syls = gen_schema[a]\n",
    "while syls < target_schema[a]:\n",
    "            new_line = aug.augment(line)\n",
    "            syls = phoney.count_syllables(new_line)\n",
    "            print(syls)\n",
    "            print(\"Original:\")\n",
    "            print(line)\n",
    "            print(\"Augmented Text:\")\n",
    "            print(new_line)\n",
    "            #If we overshoot\n",
    "            if syls > target_schema[a]:\n",
    "                print(\"oops we overshot\")\n",
    "                print(syls)\n",
    "                new_line = line\n",
    "            print(\"---------\")\n",
    "print(\"Target acquired:\")\n",
    "print(target_schema[a])\n",
    "print(\"Final line is:\")\n",
    "print(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoney = BigPhoney()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gen_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, line in enumerate(gen_lyrics):\n",
    "    new_lyrics = []\n",
    "    if (gen_schema[num] == target_schema[num]): \n",
    "        new_lyrics.append(line)\n",
    "    elif (gen_schema[num] < target_schema[num]):\n",
    "        syls = gen_schema[num]\n",
    "        while syls < target_schema[num]:\n",
    "            line = aug.augment(line)\n",
    "            syls = phoney.count_syllables(line)\n",
    "            print(syls,line)\n",
    "        new_lyrics.append(augmented_text)\n",
    "    elif ((gen_schema[num] - target_schema[num]) > 0):\n",
    "        syls = gen_schema[num]\n",
    "        words = line.split(\" \")\n",
    "        while syls > target_schema[num]:\n",
    "            del words[-1]\n",
    "            line = ' '.join(words)\n",
    "            syls = phoney.count_syllables(line)\n",
    "        new_lyrics.append(line)\n",
    "    print(new_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lyrics(gen_schema, gen_lyrics, target_schema, target_lyrics)\n",
    "    \n",
    "    new_lyrics = []\n",
    "    \n",
    "    for line in gen_lyrics\n",
    "        if (gen_schema(line) - target_schema(line)) = 0 \n",
    "            new_lyrics.append()\n",
    "            \n",
    "\n",
    "return processed_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit_lyrics(generated_text, target_schema)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
