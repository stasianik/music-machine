{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2\n",
    "from big_phoney import BigPhoney\n",
    "import numpy as np\n",
    "import lyricsgenius as genius\n",
    "import pandas as pd\n",
    "import utils\n",
    "\n",
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "\n",
    "from nlpaug.util import Action\n",
    "# model_name = \"124M\"\n",
    "# model is saved into current directory under /models/124M/\n",
    "# gpt2.download_gpt2(model_name=model_name) #need to run only once. comment out once done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models and outside functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiate TensorFlow session, needs GPU\n",
    "#Might need to start this inside the function so I can choose the right \"run\" a.k.a model\n",
    "# from timeit import default_timer as timer\n",
    "# print('import tensorflow')\n",
    "# start = timer()\n",
    "sess = gpt2.start_tf_sess()\n",
    "# end = timer()\n",
    "# print('Elapsed time: ' + str(end - start))\n",
    "\n",
    "gpt2.load_gpt2(sess, run_name='run1')\n",
    "\n",
    "#Load text augmentation model\n",
    "aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased', action=\"insert\")\n",
    "\n",
    "#For syllable counting\n",
    "phoney = BigPhoney()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "print('import tensorflow')\n",
    "start = timer()\n",
    "sess = gpt2.start_tf_sess()\n",
    "end = timer()\n",
    "print('Elapsed time: ' + str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These will go in a Utils.py file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_lyrics(artist, title):\n",
    "    \n",
    "    api_key = 'Nc3VjqRNlEZiD9mqOQATDQ5PuZ4IjdgV13n7c39OIyNwsjuazZThQlQkdr_Hts4c'\n",
    "    api = genius.Genius(api_key)\n",
    "    api.remove_section_headers = True # Removes section headers like \"Verse\" and \"Intro\"\n",
    "    \n",
    "    #get song lyrics\n",
    "    song = api.search_song(artist, title)\n",
    "    \n",
    "    #clean up the target lyrics\n",
    "    target = song.lyrics\n",
    "    target = target.replace(\"\\u2005\",\" \")\n",
    "    target = target.replace(\"\\\\\",\" \")\n",
    "    target = target.replace(\"\\\\n\",\" \")\n",
    "    target = target.replace(\"(\",\" \")\n",
    "    target = target.replace(\")\",\" \")\n",
    "    target = target.replace(\"\\n\\n\",\"\\n\")\n",
    "    target = target.replace(\"\\n\\n\\n\",\"\\n\")\n",
    "    target = target.replace(\"2x\",\"\")\n",
    "    #create list of lines\n",
    "    target_lyrics = target.split(\"\\n\")\n",
    "    print(\"Target lyrics:\")\n",
    "    print(target_lyrics)\n",
    "    return target_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later on I'll need to add the artist as a parameter, if I have 3, so it can load in the right finetuned model\n",
    "# Figure out prefix\n",
    "def generate_lyrics(): \n",
    "    \n",
    "    gen_lyrics = gpt2.generate(sess, \n",
    "                     length=250,\n",
    "                     temperature=0.9,\n",
    "                     include_prefix=False,\n",
    "                     #prefix=\"Deep in the night\",\n",
    "                     nsamples=1,\n",
    "                     batch_size=1,\n",
    "                     return_as_list=True)[0]\n",
    "    \n",
    "    gen_lyrics = gen_lyrics.split(\"\\n\")\n",
    "    \n",
    "    return gen_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_syls(text):\n",
    "    \n",
    "    schema = []\n",
    "    \n",
    "    for line in text:\n",
    "         syls = phoney.count_syllables(line)\n",
    "         schema.append(syls)\n",
    "         #print(syls,line)\n",
    "        \n",
    "    return schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The magical lyrics fitting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function uses the count_syls function above to keep track of num of syllables in each line\n",
    "def fit_lyrics(gen_lyrics, target_lyrics):\n",
    "    \n",
    "    gen_schema = count_syls(gen_lyrics)\n",
    "    target_schema = count_syls(target_lyrics)\n",
    "    \n",
    "    #make generated lyrics same length as target lyrics\n",
    "    target_len = len(target_schema)\n",
    "    del gen_schema[target_len:]\n",
    "    del gen_lyrics[target_len:]\n",
    "\n",
    "    print(target_schema)\n",
    "    new_lyrics = []\n",
    "    \n",
    "    for num, line in enumerate(gen_lyrics):\n",
    "        print(num)\n",
    "        if (gen_schema[num] == target_schema[num]): \n",
    "            new_lyrics.append(line)\n",
    "        elif (gen_schema[num] < target_schema[num]):\n",
    "            syls = gen_schema[num]\n",
    "            while syls < target_schema[num]:\n",
    "                original_line = line\n",
    "                line = aug.augment(line)\n",
    "                syls = phoney.count_syllables(line)\n",
    "                #In case we overshoot (add too many syllables)\n",
    "                if syls > target_schema[num]:\n",
    "                    #print(\"Oops we overshot\")\n",
    "                    #target = target_schema[num]\n",
    "                    line = original_line\n",
    "            new_lyrics.append(line)\n",
    "        elif (gen_schema[num] > target_schema[num]):\n",
    "            syls = gen_schema[num]\n",
    "            words = line.split(\" \")\n",
    "            while syls > target_schema[num]:\n",
    "                del words[-1]\n",
    "                new_line = ' '.join(words)\n",
    "                syls = phoney.count_syllables(new_line)\n",
    "                #In case too many syllables are deleted\n",
    "                if syls < target_schema[num]:\n",
    "                    #print(\"Oops, deleted too many\")\n",
    "                    new_line = aug.augment(new_line)\n",
    "                    syls = phoney.count_syllables(new_line)\n",
    "                    #print(syls)\n",
    "                #print(syls)\n",
    "            new_lyrics.append(new_line)\n",
    "    print(\"New lyrics:\")\n",
    "    print(new_lyrics)\n",
    "    \n",
    "    return new_lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to test everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = \"Idina Menzel\"\n",
    "title = \"Let it go\"\n",
    "target_lyrics = get_target_lyrics(artist, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_lyrics = generate_lyrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_lyrics(gen_lyrics, target_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gen_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_schema)\n",
    "print(gen_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "print('import tensorflow')\n",
    "start = timer()\n",
    "import tensorflow\n",
    "end = timer()\n",
    "print('Elapsed time: ' + str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
